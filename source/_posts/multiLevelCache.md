---
title: 多级缓存 （上）
tags: [多级缓存]
categories: 缓存
---
## 写在开头
>最近跟业务团队交流的时候，发现不少的业务团队都有一些分布式缓存无法解决的痛点，个别业务团队也正在尝试通过使用本地缓存来解决这些问题。由此，在本文中聊聊多级缓存。

>通过本文您可以了解到：


>* 业务有哪些分布式缓存无法解决的痛点
>* 多级缓存如何来解决这些问题
>* 使用本地缓存应该注意哪些问题
>* 本地缓存的类型和差异有哪些

## 业务痛点
### 批量查询
假如有商品信息通过商品ID散列分布在不同的分布式缓存节点上，应用需要批量查询一堆商品信息。

如果运气好缓存使用了proxy或者cluster那么至少它们还支持批量查询，但是proxy也得先把key进行分组然后分批到不同的节点上查询再聚合返回。否则如果应用用的是client sharding的话，很不幸你用的客户端可能连这个聚合的功能都没有，那么你还得自己开发类似proxy实现的聚合功能。

另外，这种批量查询并聚合的效率显然过低，如果现在业务有大量的批量查询商品信息的请求，这个会极大的影响应用的吞吐能力。

### 热键
同样以商品为例，如果我们的某个商品是爆款，那么一个缓存节点可能也无法支撑该商品过高的QPS。尤其是在大促或者一些特俗的业务场景如秒杀的时候，该问题表现的尤为突出。

### 高可靠性
一旦分布式缓存的节点故障，大量请求需要回源到后端的存储如数据库或者回源到后端的服务，此时可能会导致数据库或者后端的服务也瞬间负载过高无法提供服务导致雪崩的情况。或许你会说Redis不是支持主从吗？实际上从发现主节点故障到选择一个新的从节点变成主节点是有一个若干分钟的恢复期的，那么后端的回源通道是否能支撑这段时间的流量是个问题。


## 多级缓存
那么如何来解决以上的这些问题呢？

一个可行的方案就是通过引入本地缓存作为一级缓存来缓存热点数据，原有的分布式缓存变成二级缓存组成多级缓存。一级缓存设置较短的过期时间，二级缓存设置较长的过期时间。把80%的流量控制在一级缓存，剩余的20%流量可以回源到二级缓存或者后端的其他回源通道（比例只是示例，不同场景不一样）。不但有效的提高了查询的效率也进一步的提高了可靠性。

![流程](/images/multilevelcache1/process.jpg)

当然本地缓存的过期时间和二级缓存并不是必须的，本地缓存根据场景大致可以分成缓存和存储两种：

场景  | 缓存数据 | 过期/淘汰策略 | 缓存更新 | 二级缓存 | 描述
------------- | ------------- | ------------- | ------------- | ------------- | -------------
缓存  | 热点数据 | TTL/LFU/LRU | 主动更新/被动更新（取决于一致性要求）| Y | 适合数据量大只缓存热点数据的场景
存储  | 全量数据 | 永不过期 | 被动更新 | N | 适合数据量小回源成本较高的场景

## 新的坑
通过多级缓存铺平了原来的坑，但是转身发现为了埋坑又挖了一堆新的坑, 心累！
![单身狗挖坑](/images/multilevelcache1/keng.jpg)

### 缓存更新
当数据发生变化时如何能够及时更新到本地缓存呢？缓存的更新又需要注意些什么呢？

通常来说缓存更新有以下两种方式：

* 主动更新：适合一致性要求不高但更新较为频繁的场景。应用可以设置一个较短的缓存过期时间，当缓存过期后回源查询后更新到缓存。好处是架构比较简单，不需要依赖额外的数据同步通道。
* 被动更新：适合一致性要求较高但更新不太频繁的场景。比如：商品价格等。应用设置较长的过期时间或者不过期，通过数据同步通道同步数据变更到缓存。

当一致性和更新频率都高的情况下，则优先考虑实时性，可以使用被动更新的模式。比如库存。

当需要被动更新时，一个有效的数据同步通道至少满足以下几个需求：

* 及时：当数据发生变化时本地缓存需要通过第一时间得到最新的数据，如库存的变化
* 可靠：数据同步通道需要保证变化的数据一定能够通知到本地缓存，不能丢数据，尤其是针对把本地缓存当做存储来用的业务场景。
* 有序：数据同步通道需要保证数据变更通知尽量有序的到达，尤其针对一些敏感数据的更新，如价格、库存，虽然最终还是会通过数据库来保证数据的一致性，但是用户端依然会出现一些用户体验不好的情况。
* 支持pubsub：当有一个应用有多个实例，或者有多个应用都存在本地缓存时一份数据的变化需要同时广播到所有实例或者应用。

从以上需求不难发现以上也基本上是消息所具备的特性，所以消息也就成为了本地缓存数据同步机制的不二选择。

### 缓存重建
当应用重启后为了防止大量请求穿透到后端，应用在提供服务之前需要通过重建本地的缓存进行预热。

有两种方式：

* 回源二级缓存、数据库或者后端的服务进行查询。该方式的弊端是如果本地的缓存数据量比较大会造成预热时间较长，预热周期内无法提供服务。为了减少预热的时间可以考虑并行预热，但是也要考虑不能对后端的服务造成过大的压力。
* 本地缓存持久化。该方式的弊端是首先本地缓存框架需要有一个可靠的持久化机制，同时还要考虑停机期间增量数据如何同步的问题。一种方式是通过消息中间件进行回溯消费，但是应用端需要保存回溯的起点。

### 监控管理
有了本地缓存后，我们还得考虑本地缓存的监控和管理。本地缓存不像分布式缓存，有较多的监控和管理的机制和手段可以提供支持。至少需要考虑以下一些点：

* 监控点：命中率、缓存的总空间大小、空间使用率、各个命令的QPS、缓存的最后更新时间、rehash的次数
* 告警：空间使用率告警、命中率告警（可选）
* 管理：通过命令或者管理平台可以进行数据查询、脏数据清理、缓存开关等等

### 架构
结合以上的问题和解决办法，新的缓存架构应该是这样的。

![architecture](/images/multilevelcache1/cachearchitecture.jpg)

## 缓存的选型

从JVM的角度来说分堆内堆外两种，区别主要在于对GC的影响。

类别  | 吞吐量 | 序列化 | GC影响 | 适合场景
------------- | ------------- | ------------- | ------------- | -------------
堆内  | 高 | 无 | 大 | 数据量小、更新不频繁
堆外  | 低 | 有 | 无 | 数据量大、更新频繁
 
* 序列化：由于JAVA对象本身就保存在堆内所以不存在序列化的问题，而使用堆外缓存时则需要考虑一种高效的序列化机制，把序列化好的数据缓存到缓存中。
* GC影响：堆内的主要一个弊端是对GC影响较大，如果更新新频率高则单位时间内产生的对象较多则GC的触发频率会加大，系统吞吐能力会下降。另外，如果存活的数据量大则GC时标记的对象过多会导致STW的时间过长，RT就会变大。

所以不同的场景可以考虑使用不同的类型的本地缓存。

当然即使增加了序列化的成本，堆外缓存的QPS依然是在几百万的数量级，所以应该足以满足应用的需求。

## 写在最后

* 上面提到如果使用堆外缓存需要考虑序列化的问题，那么又需要注意些什么地方呢？
* 堆外缓存又有哪些开源方案？
* 堆外缓存的容量评估又需要注意些什么？

后面文章我们会再详细分析，敬请关注！



